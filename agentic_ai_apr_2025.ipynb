{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"pydantic-ai[logfire]\" \"nest_asyncio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06:17:25.969 OpenAI Agents trace: Agent workflow\n",
      "06:17:25.969   Agent run: 'Research Assistant'\n",
      "06:17:25.970     Responses API with 'gpt-4o'\n",
      "The paper with the identifier arXiv:1706.03762 is titled \"Attention Is All You Need.\" Here is the abstract:\n",
      "\n",
      "\"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We are releasing our models and code to serve as a starting point for further work on this line of research.\"\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, Runner\n",
    "\n",
    "import logfire\n",
    "# configure Logfire for console only\n",
    "logfire.configure(\n",
    "    service_name=\"my_agent_service\",\n",
    "    send_to_logfire=False,\n",
    "    inspect_arguments=True\n",
    ")\n",
    "logfire.instrument_openai_agents()\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Research Assistant\",\n",
    "    instructions=\"You are a helpful Research Assistant which helps professors in various tasks.\",\n",
    ")\n",
    "\n",
    "result = await Runner.run(agent, \"Get me the abstract of arXiv:1706.03762\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06:17:31.294 OpenAI Agents trace: Agent workflow\n",
      "06:17:31.295   Agent run: 'Research Assistant'\n",
      "06:17:31.297     Responses API with 'gpt-4o'\n",
      "06:17:32.132     Function: fetch_paper\n",
      "06:17:32.188     Responses API with 'gpt-4o'\n",
      "The abstract for the paper titled \"Attention Is All You Need\" (arXiv:1706.03762) is as follows:\n",
      "\n",
      "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\n",
      "\n",
      "For more details, you can access the full paper [here](https://arxiv.org/pdf/1706.03762.pdf).\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import Dict, Any\n",
    "from agents import function_tool\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def fetch_paper(arxiv_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fetches paper information from arXiv given its ID.\n",
    "    \n",
    "    Args:\n",
    "        arxiv_id: The arXiv ID (e.g., '1706.03762')\n",
    "    \n",
    "    Returns:\n",
    "        A dictionary containing paper information including:\n",
    "        - title\n",
    "        - authors\n",
    "        - abstract\n",
    "        - pdf_url\n",
    "        - published_date\n",
    "    \"\"\"\n",
    "    # Clean the input ID\n",
    "    arxiv_id = arxiv_id.strip().replace(\"arXiv:\", \"\")\n",
    "    \n",
    "    # Construct the URL\n",
    "    url = f\"https://arxiv.org/abs/{arxiv_id}\"\n",
    "    \n",
    "    try:\n",
    "        # Fetch the page\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse HTML\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Extract paper information\n",
    "        title = soup.select_one(\"h1.title\").text.replace(\"Title:\", \"\").strip()\n",
    "        authors = [author.strip() for author in soup.select_one(\"div.authors\").text.replace(\"Authors:\", \"\").split(\",\")]\n",
    "        abstract = soup.select_one(\"blockquote.abstract\").text.replace(\"Abstract:\", \"\").strip()\n",
    "        pdf_url = f\"https://arxiv.org/pdf/{arxiv_id}.pdf\"\n",
    "        \n",
    "        # Try to extract published date\n",
    "        date_element = soup.select_one(\"div.dateline\")\n",
    "        published_date = date_element.text.strip() if date_element else \"Date not found\"\n",
    "        \n",
    "        return {\n",
    "            \"title\": title,\n",
    "            \"authors\": authors,\n",
    "            \"abstract\": abstract,\n",
    "            \"pdf_url\": pdf_url,\n",
    "            \"published_date\": published_date,\n",
    "            \"arxiv_id\": arxiv_id\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching paper: {e}\")\n",
    "        return {\n",
    "            \"error\": str(e),\n",
    "            \"arxiv_id\": arxiv_id\n",
    "        }\n",
    "\n",
    "\n",
    "agent_1 = Agent(\n",
    "    name=\"Research Assistant\",\n",
    "    instructions=\"You are a helpful Research Assistant which helps professors in various tasks.\",\n",
    "    tools=[fetch_paper]\n",
    ")\n",
    "\n",
    "result = await Runner.run(agent_1, \"Get me the abstract of arXiv:1706.03762\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06:04:36.688 OpenAI Agents trace: Agent workflow\n",
      "06:04:36.688   Agent run: 'Research Assistant'\n",
      "06:04:36.689     Responses API with 'gpt-4o'\n",
      "06:04:37.627     Function: fetch_paper\n",
      "06:04:37.684     Responses API with 'gpt-4o'\n",
      "06:04:38.916     Function: fetch_paper\n",
      "06:04:38.972     Responses API with 'gpt-4o'\n",
      "### Abstract\n",
      "\n",
      "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\n",
      "\n",
      "### Author Affiliations\n",
      "To find the current affiliations of the authors, I would need to perform additional searches as the arXiv entry does not provide current employment details. Would you like me to look up this information?\n"
     ]
    }
   ],
   "source": [
    "result = await Runner.run(agent_1, \"Get me the abstract of arXiv:1706.03762 and tell me where each author is working currently\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:openai.agents:Creating trace Agent workflow with id trace_33433db04de2478aaf2e76dde17f8025\n",
      "DEBUG:openai.agents:Setting current trace: trace_33433db04de2478aaf2e76dde17f8025\n",
      "DEBUG:openai.agents:Creating span <agents.tracing.span_data.AgentSpanData object at 0x11ea14cb0> with id None\n",
      "DEBUG:openai.agents:Running agent Research Assistant (turn 1)\n",
      "DEBUG:openai.agents:Creating span <agents.tracing.span_data.ResponseSpanData object at 0x11c0b6080> with id None\n",
      "DEBUG:openai.agents:Calling LLM gpt-4o with input:\n",
      "[\n",
      "  {\n",
      "    \"content\": \"Get me the abstract of arXiv:1706.03762 and tell me where each author is working currently.\",\n",
      "    \"role\": \"user\"\n",
      "  }\n",
      "]\n",
      "Tools:\n",
      "[\n",
      "  {\n",
      "    \"type\": \"web_search_preview\",\n",
      "    \"user_location\": null,\n",
      "    \"search_context_size\": \"medium\"\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"fetch_paper\",\n",
      "    \"parameters\": {\n",
      "      \"properties\": {\n",
      "        \"arxiv_id\": {\n",
      "          \"description\": \"The arXiv ID (e.g., '1706.03762')\",\n",
      "          \"title\": \"Arxiv Id\",\n",
      "          \"type\": \"string\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"arxiv_id\"\n",
      "      ],\n",
      "      \"title\": \"fetch_paper_args\",\n",
      "      \"type\": \"object\",\n",
      "      \"additionalProperties\": false\n",
      "    },\n",
      "    \"strict\": true,\n",
      "    \"type\": \"function\",\n",
      "    \"description\": \"Fetches paper information from arXiv given its ID.\"\n",
      "  }\n",
      "]\n",
      "Stream: False\n",
      "Tool choice: NOT_GIVEN\n",
      "Response format: NOT_GIVEN\n",
      "Previous response id: None\n",
      "\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/responses', 'headers': {'User-Agent': 'Agents/Python 0.0.11'}, 'files': None, 'json_data': {'input': [{'content': 'Get me the abstract of arXiv:1706.03762 and tell me where each author is working currently.', 'role': 'user'}], 'model': 'gpt-4o', 'include': [], 'instructions': '\\nYou are a helpful Research Assistant which helps professors in various tasks.\\nMake sure to answer all questions asked. When asked about current information,\\nuse the WebSearchTool to find the latest information.\\n', 'stream': False, 'tools': [{'type': 'web_search_preview', 'user_location': None, 'search_context_size': 'medium'}, {'name': 'fetch_paper', 'parameters': {'properties': {'arxiv_id': {'description': \"The arXiv ID (e.g., '1706.03762')\", 'title': 'Arxiv Id', 'type': 'string'}}, 'required': ['arxiv_id'], 'title': 'fetch_paper_args', 'type': 'object', 'additionalProperties': False}, 'strict': True, 'type': 'function', 'description': 'Fetches paper information from arXiv given its ID.'}]}}\n",
      "DEBUG:httpcore.connection:close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11c264d90>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x11bc45010> server_hostname='api.openai.com' timeout=5.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11c040810>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06:29:33.990 OpenAI Agents trace: Agent workflow\n",
      "06:29:33.991   Agent run: 'Research Assistant'\n",
      "06:29:33.995     Responses API with 'gpt-4o'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 20 Apr 2025 06:29:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-thoiewvv8uw64smqtyk9d229'), (b'x-request-id', b'req_37e23106ebdd65def9ab421c09cf6759'), (b'openai-processing-ms', b'652'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'933296880c86df86-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/responses \"200 OK\"\n",
      "DEBUG:openai.agents:LLM resp:\n",
      "[\n",
      "  {\n",
      "    \"arguments\": \"{\\\"arxiv_id\\\":\\\"1706.03762\\\"}\",\n",
      "    \"call_id\": \"call_OLuKxu3siD9x6ZKJWYvoUmbB\",\n",
      "    \"name\": \"fetch_paper\",\n",
      "    \"type\": \"function_call\",\n",
      "    \"id\": \"fc_6804944ea78c81918da5526884b652e006f1cd009a6b7fe3\",\n",
      "    \"status\": \"completed\"\n",
      "  }\n",
      "]\n",
      "\n",
      "DEBUG:openai.agents:Creating span <agents.tracing.span_data.FunctionSpanData object at 0x11e01f890> with id None\n",
      "DEBUG:openai.agents:Invoking tool fetch_paper with input {\"arxiv_id\":\"1706.03762\"}\n",
      "DEBUG:openai.agents:Tool call args: ['1706.03762'], kwargs: {}\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): arxiv.org:443\n",
      "DEBUG:urllib3.connectionpool:https://arxiv.org:443 \"GET /abs/1706.03762 HTTP/1.1\" 200 49883\n",
      "DEBUG:openai.agents:Tool fetch_paper returned {'title': 'Attention Is All You Need', 'authors': ['Ashish Vaswani', 'Noam Shazeer', 'Niki Parmar', 'Jakob Uszkoreit', 'Llion Jones', 'Aidan N. Gomez', 'Lukasz Kaiser', 'Illia Polosukhin'], 'abstract': 'The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.', 'pdf_url': 'https://arxiv.org/pdf/1706.03762.pdf', 'published_date': '[Submitted on 12 Jun 2017 (v1), last revised 2 Aug 2023 (this version, v7)]', 'arxiv_id': '1706.03762'}\n",
      "DEBUG:openai.agents:Running agent Research Assistant (turn 2)\n",
      "DEBUG:openai.agents:Creating span <agents.tracing.span_data.ResponseSpanData object at 0x11e9a66c0> with id None\n",
      "DEBUG:openai.agents:Calling LLM gpt-4o with input:\n",
      "[\n",
      "  {\n",
      "    \"content\": \"Get me the abstract of arXiv:1706.03762 and tell me where each author is working currently.\",\n",
      "    \"role\": \"user\"\n",
      "  },\n",
      "  {\n",
      "    \"arguments\": \"{\\\"arxiv_id\\\":\\\"1706.03762\\\"}\",\n",
      "    \"call_id\": \"call_OLuKxu3siD9x6ZKJWYvoUmbB\",\n",
      "    \"name\": \"fetch_paper\",\n",
      "    \"type\": \"function_call\",\n",
      "    \"id\": \"fc_6804944ea78c81918da5526884b652e006f1cd009a6b7fe3\",\n",
      "    \"status\": \"completed\"\n",
      "  },\n",
      "  {\n",
      "    \"call_id\": \"call_OLuKxu3siD9x6ZKJWYvoUmbB\",\n",
      "    \"output\": \"{'title': 'Attention Is All You Need', 'authors': ['Ashish Vaswani', 'Noam Shazeer', 'Niki Parmar', 'Jakob Uszkoreit', 'Llion Jones', 'Aidan N. Gomez', 'Lukasz Kaiser', 'Illia Polosukhin'], 'abstract': 'The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.', 'pdf_url': 'https://arxiv.org/pdf/1706.03762.pdf', 'published_date': '[Submitted on 12 Jun 2017 (v1), last revised 2 Aug 2023 (this version, v7)]', 'arxiv_id': '1706.03762'}\",\n",
      "    \"type\": \"function_call_output\"\n",
      "  }\n",
      "]\n",
      "Tools:\n",
      "[\n",
      "  {\n",
      "    \"type\": \"web_search_preview\",\n",
      "    \"user_location\": null,\n",
      "    \"search_context_size\": \"medium\"\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"fetch_paper\",\n",
      "    \"parameters\": {\n",
      "      \"properties\": {\n",
      "        \"arxiv_id\": {\n",
      "          \"description\": \"The arXiv ID (e.g., '1706.03762')\",\n",
      "          \"title\": \"Arxiv Id\",\n",
      "          \"type\": \"string\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"arxiv_id\"\n",
      "      ],\n",
      "      \"title\": \"fetch_paper_args\",\n",
      "      \"type\": \"object\",\n",
      "      \"additionalProperties\": false\n",
      "    },\n",
      "    \"strict\": true,\n",
      "    \"type\": \"function\",\n",
      "    \"description\": \"Fetches paper information from arXiv given its ID.\"\n",
      "  }\n",
      "]\n",
      "Stream: False\n",
      "Tool choice: NOT_GIVEN\n",
      "Response format: NOT_GIVEN\n",
      "Previous response id: None\n",
      "\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/responses', 'headers': {'User-Agent': 'Agents/Python 0.0.11'}, 'files': None, 'json_data': {'input': [{'content': 'Get me the abstract of arXiv:1706.03762 and tell me where each author is working currently.', 'role': 'user'}, {'arguments': '{\"arxiv_id\":\"1706.03762\"}', 'call_id': 'call_OLuKxu3siD9x6ZKJWYvoUmbB', 'name': 'fetch_paper', 'type': 'function_call', 'id': 'fc_6804944ea78c81918da5526884b652e006f1cd009a6b7fe3', 'status': 'completed'}, {'call_id': 'call_OLuKxu3siD9x6ZKJWYvoUmbB', 'output': \"{'title': 'Attention Is All You Need', 'authors': ['Ashish Vaswani', 'Noam Shazeer', 'Niki Parmar', 'Jakob Uszkoreit', 'Llion Jones', 'Aidan N. Gomez', 'Lukasz Kaiser', 'Illia Polosukhin'], 'abstract': 'The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.', 'pdf_url': 'https://arxiv.org/pdf/1706.03762.pdf', 'published_date': '[Submitted on 12 Jun 2017 (v1), last revised 2 Aug 2023 (this version, v7)]', 'arxiv_id': '1706.03762'}\", 'type': 'function_call_output'}], 'model': 'gpt-4o', 'include': [], 'instructions': '\\nYou are a helpful Research Assistant which helps professors in various tasks.\\nMake sure to answer all questions asked. When asked about current information,\\nuse the WebSearchTool to find the latest information.\\n', 'stream': False, 'tools': [{'type': 'web_search_preview', 'user_location': None, 'search_context_size': 'medium'}, {'name': 'fetch_paper', 'parameters': {'properties': {'arxiv_id': {'description': \"The arXiv ID (e.g., '1706.03762')\", 'title': 'Arxiv Id', 'type': 'string'}}, 'required': ['arxiv_id'], 'title': 'fetch_paper_args', 'type': 'object', 'additionalProperties': False}, 'strict': True, 'type': 'function', 'description': 'Fetches paper information from arXiv given its ID.'}]}}\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06:29:34.900     Function: fetch_paper\n",
      "06:29:34.951     Responses API with 'gpt-4o'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 20 Apr 2025 06:29:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-thoiewvv8uw64smqtyk9d229'), (b'x-request-id', b'req_f9a07f9c801ad17a2f979f5ac74b9d5b'), (b'openai-processing-ms', b'19686'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9332968dc8a7df86-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/responses \"200 OK\"\n",
      "DEBUG:openai.agents:LLM resp:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"ws_6804944fe3108191baf5d411b5091e6406f1cd009a6b7fe3\",\n",
      "    \"status\": \"completed\",\n",
      "    \"type\": \"web_search_call\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"msg_680494528aac8191b56487408ace7da806f1cd009a6b7fe3\",\n",
      "    \"content\": [\n",
      "      {\n",
      "        \"annotations\": [\n",
      "          {\n",
      "            \"end_index\": 786,\n",
      "            \"start_index\": 702,\n",
      "            \"title\": \"Ashish Vaswani\",\n",
      "            \"type\": \"url_citation\",\n",
      "            \"url\": \"https://en.wikipedia.org/wiki/Ashish_Vaswani?utm_source=openai\"\n",
      "          },\n",
      "          {\n",
      "            \"end_index\": 983,\n",
      "            \"start_index\": 857,\n",
      "            \"title\": \"Authors of Attention Is All That You Need Paper (2017) \\u2013 Marketing Ganga\",\n",
      "            \"type\": \"url_citation\",\n",
      "            \"url\": \"https://www.marketingganga.com/authors-of-attention-is-all-that-you-need-paper-2017/?utm_source=openai\"\n",
      "          }\n",
      "        ],\n",
      "        \"text\": \"The paper titled \\\"Attention Is All You Need\\\" introduces the Transformer, a novel network architecture based solely on attention mechanisms, eliminating the need for recurrence and convolutions. This design enhances parallelization and reduces training time. The Transformer achieved superior performance in machine translation tasks, notably obtaining a BLEU score of 28.4 on the WMT 2014 English-to-German translation task and 41.8 on the English-to-French task. Additionally, the model demonstrated effective generalization to other tasks, such as English constituency parsing.\\n\\nRegarding the current affiliations of the authors:\\n\\n- **Ashish Vaswani**: Co-founder and CEO of Essential AI since 2022. ([en.wikipedia.org](https://en.wikipedia.org/wiki/Ashish_Vaswani?utm_source=openai))\\n\\n- **Noam Shazeer**: CEO of Character AI, Palo Alto, California, USA. ([marketingganga.com](https://www.marketingganga.com/authors-of-attention-is-all-that-you-need-paper-2017/?utm_source=openai))\\n\\n- **Niki Parmar**: No current affiliation found.\\n\\n- **Jakob Uszkoreit**: No current affiliation found.\\n\\n- **Llion Jones**: No current affiliation found.\\n\\n- **Aidan N. Gomez**: No current affiliation found.\\n\\n- **Lukasz Kaiser**: No current affiliation found.\\n\\n- **Illia Polosukhin**: No current affiliation found.\\n\\nPlease note that the affiliations of the other authors are not readily available in the provided sources. \",\n",
      "        \"type\": \"output_text\"\n",
      "      }\n",
      "    ],\n",
      "    \"role\": \"assistant\",\n",
      "    \"status\": \"completed\",\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"ws_6804945563a881918abcda1942d24d7506f1cd009a6b7fe3\",\n",
      "    \"status\": \"completed\",\n",
      "    \"type\": \"web_search_call\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"msg_68049456cf408191a85e7df31847a50f06f1cd009a6b7fe3\",\n",
      "    \"content\": [\n",
      "      {\n",
      "        \"annotations\": [\n",
      "          {\n",
      "            \"end_index\": 954,\n",
      "            \"start_index\": 820,\n",
      "            \"title\": \"How Niki Parmar Went From Self-Taught Coder To Modern AI Pioneer\",\n",
      "            \"type\": \"url_citation\",\n",
      "            \"url\": \"https://www.ndtv.com/india-ai/how-niki-parmar-went-from-self-taught-coder-to-modern-ai-pioneer-6706892?utm_source=openai\"\n",
      "          }\n",
      "        ],\n",
      "        \"text\": \"The paper titled \\\"Attention Is All You Need\\\" introduces the Transformer, a novel network architecture based solely on attention mechanisms, eliminating the need for recurrence and convolutions. This design enhances parallelization and reduces training time. The Transformer achieved superior performance in machine translation tasks, notably obtaining a BLEU score of 28.4 on the WMT 2014 English-to-German translation task and 41.8 on the English-to-French task. Additionally, the model demonstrated effective generalization to other tasks, such as English constituency parsing.\\n\\nRegarding the current affiliations of the authors:\\n\\n- **Ashish Vaswani**: Co-founder and CEO of Essential AI since 2022.\\n\\n- **Noam Shazeer**: CEO of Character AI, Palo Alto, California, USA.\\n\\n- **Niki Parmar**: Co-founder of Essential AI. ([ndtv.com](https://www.ndtv.com/india-ai/how-niki-parmar-went-from-self-taught-coder-to-modern-ai-pioneer-6706892?utm_source=openai))\\n\\n- **Jakob Uszkoreit**: No current affiliation found.\\n\\n- **Llion Jones**: No current affiliation found.\\n\\n- **Aidan N. Gomez**: No current affiliation found.\\n\\n- **Lukasz Kaiser**: No current affiliation found.\\n\\n- **Illia Polosukhin**: No current affiliation found.\\n\\nPlease note that the affiliations of the other authors are not readily available in the provided sources. \",\n",
      "        \"type\": \"output_text\"\n",
      "      }\n",
      "    ],\n",
      "    \"role\": \"assistant\",\n",
      "    \"status\": \"completed\",\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"ws_6804945958ac81918557c9140158806306f1cd009a6b7fe3\",\n",
      "    \"status\": \"completed\",\n",
      "    \"type\": \"web_search_call\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"msg_6804945b6bfc8191ba80937428bb0fd806f1cd009a6b7fe3\",\n",
      "    \"content\": [\n",
      "      {\n",
      "        \"annotations\": [\n",
      "          {\n",
      "            \"end_index\": 1035,\n",
      "            \"start_index\": 888,\n",
      "            \"title\": \"Inceptive CEO Jakob Uszkoreit On Transformers And Using AI To Make New Drugs - CNBC Africa\",\n",
      "            \"type\": \"url_citation\",\n",
      "            \"url\": \"https://www.cnbcafrica.com/2024/inceptive-ceo-jakob-uszkoreit-on-transformers-and-using-ai-to-make-new-drugs/?utm_source=openai\"\n",
      "          }\n",
      "        ],\n",
      "        \"text\": \"The paper titled \\\"Attention Is All You Need\\\" introduces the Transformer, a novel network architecture based solely on attention mechanisms, eliminating the need for recurrence and convolutions. This design enhances parallelization and reduces training time. The Transformer achieved superior performance in machine translation tasks, notably obtaining a BLEU score of 28.4 on the WMT 2014 English-to-German translation task and 41.8 on the English-to-French task. Additionally, the model demonstrated effective generalization to other tasks, such as English constituency parsing.\\n\\nRegarding the current affiliations of the authors:\\n\\n- **Ashish Vaswani**: Co-founder and CEO of Essential AI since 2022.\\n\\n- **Noam Shazeer**: CEO of Character AI, Palo Alto, California, USA.\\n\\n- **Niki Parmar**: Co-founder of Essential AI.\\n\\n- **Jakob Uszkoreit**: Co-founder and CEO of Inceptive since 2021. ([cnbcafrica.com](https://www.cnbcafrica.com/2024/inceptive-ceo-jakob-uszkoreit-on-transformers-and-using-ai-to-make-new-drugs/?utm_source=openai))\\n\\n- **Llion Jones**: No current affiliation found.\\n\\n- **Aidan N. Gomez**: No current affiliation found.\\n\\n- **Lukasz Kaiser**: No current affiliation found.\\n\\n- **Illia Polosukhin**: No current affiliation found.\\n\\nPlease note that the affiliations of the other authors are not readily available in the provided sources. \",\n",
      "        \"type\": \"output_text\"\n",
      "      }\n",
      "    ],\n",
      "    \"role\": \"assistant\",\n",
      "    \"status\": \"completed\",\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"ws_6804945dfbb88191adf8877c2632011d06f1cd009a6b7fe3\",\n",
      "    \"status\": \"completed\",\n",
      "    \"type\": \"web_search_call\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"msg_6804945f919c819199b447415483390a06f1cd009a6b7fe3\",\n",
      "    \"content\": [\n",
      "      {\n",
      "        \"annotations\": [\n",
      "          {\n",
      "            \"end_index\": 1039,\n",
      "            \"start_index\": 951,\n",
      "            \"title\": \"Llion Jones - Co-founder at Sakana AI | The Org\",\n",
      "            \"type\": \"url_citation\",\n",
      "            \"url\": \"https://theorg.com/org/sakana-ai/org-chart/llion-jones?utm_source=openai\"\n",
      "          }\n",
      "        ],\n",
      "        \"text\": \"The paper titled \\\"Attention Is All You Need\\\" introduces the Transformer, a novel network architecture based solely on attention mechanisms, eliminating the need for recurrence and convolutions. This design enhances parallelization and reduces training time. The Transformer achieved superior performance in machine translation tasks, notably obtaining a BLEU score of 28.4 on the WMT 2014 English-to-German translation task and 41.8 on the English-to-French task. Additionally, the model demonstrated effective generalization to other tasks, such as English constituency parsing.\\n\\nRegarding the current affiliations of the authors:\\n\\n- **Ashish Vaswani**: Co-founder and CEO of Essential AI since 2022.\\n\\n- **Noam Shazeer**: CEO of Character AI, Palo Alto, California, USA.\\n\\n- **Niki Parmar**: Co-founder of Essential AI.\\n\\n- **Jakob Uszkoreit**: Co-founder and CEO of Inceptive since 2021.\\n\\n- **Llion Jones**: Co-founder at Sakana AI since August 2023. ([theorg.com](https://theorg.com/org/sakana-ai/org-chart/llion-jones?utm_source=openai))\\n\\n- **Aidan N. Gomez**: CEO and co-founder of Cohere, a company specializing in large language models.\\n\\n- **Lukasz Kaiser**: Currently a researcher at OpenAI, focusing on AI and machine learning.\\n\\n- **Illia Polosukhin**: Co-founder of NEAR Protocol, a blockchain platform for decentralized applications.\\n\\nPlease note that affiliations can change over time, and the above information is based on the latest available data. \",\n",
      "        \"type\": \"output_text\"\n",
      "      }\n",
      "    ],\n",
      "    \"role\": \"assistant\",\n",
      "    \"status\": \"completed\",\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "DEBUG:openai.agents:Resetting current trace\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paper titled \"Attention Is All You Need\" introduces the Transformer, a novel network architecture based solely on attention mechanisms, eliminating the need for recurrence and convolutions. This design enhances parallelization and reduces training time. The Transformer achieved superior performance in machine translation tasks, notably obtaining a BLEU score of 28.4 on the WMT 2014 English-to-German translation task and 41.8 on the English-to-French task. Additionally, the model demonstrated effective generalization to other tasks, such as English constituency parsing.\n",
      "\n",
      "Regarding the current affiliations of the authors:\n",
      "\n",
      "- **Ashish Vaswani**: Co-founder and CEO of Essential AI since 2022.\n",
      "\n",
      "- **Noam Shazeer**: CEO of Character AI, Palo Alto, California, USA.\n",
      "\n",
      "- **Niki Parmar**: Co-founder of Essential AI.\n",
      "\n",
      "- **Jakob Uszkoreit**: Co-founder and CEO of Inceptive since 2021.\n",
      "\n",
      "- **Llion Jones**: Co-founder at Sakana AI since August 2023. ([theorg.com](https://theorg.com/org/sakana-ai/org-chart/llion-jones?utm_source=openai))\n",
      "\n",
      "- **Aidan N. Gomez**: CEO and co-founder of Cohere, a company specializing in large language models.\n",
      "\n",
      "- **Lukasz Kaiser**: Currently a researcher at OpenAI, focusing on AI and machine learning.\n",
      "\n",
      "- **Illia Polosukhin**: Co-founder of NEAR Protocol, a blockchain platform for decentralized applications.\n",
      "\n",
      "Please note that affiliations can change over time, and the above information is based on the latest available data. \n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from agents import WebSearchTool\n",
    "\n",
    "\n",
    "# Set logging level to debug\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "agent_2 = Agent(\n",
    "    name=\"Research Assistant\",\n",
    "    instructions=\n",
    "    \"\"\"\n",
    "You are a helpful Research Assistant which helps professors in various tasks.\n",
    "Make sure to answer all questions asked. When asked about current information,\n",
    "use the WebSearchTool to find the latest information.\n",
    "\"\"\",\n",
    "    tools=[WebSearchTool(), fetch_paper],\n",
    ")\n",
    "\n",
    "result = await Runner.run(\n",
    "    agent_2,\n",
    "    \"Get me the abstract of arXiv:1706.03762 and tell me where each author is working currently.\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:openai.agents:Creating trace Agent workflow with id trace_9b2e5cf3e03844bb9e448951f3433878\n",
      "DEBUG:openai.agents:Setting current trace: trace_9b2e5cf3e03844bb9e448951f3433878\n",
      "DEBUG:openai.agents:Creating span <agents.tracing.span_data.AgentSpanData object at 0x11e727890> with id None\n",
      "DEBUG:openai.agents:Running agent Research Assistant (turn 1)\n",
      "DEBUG:openai.agents:Creating span <agents.tracing.span_data.ResponseSpanData object at 0x11e024960> with id None\n",
      "DEBUG:openai.agents:Calling LLM gpt-4o with input:\n",
      "[\n",
      "  {\n",
      "    \"content\": \"check my draft proposal at draft_proposal.txt and give me feedback on it based on what is currently available in the web about this topic\",\n",
      "    \"role\": \"user\"\n",
      "  }\n",
      "]\n",
      "Tools:\n",
      "[\n",
      "  {\n",
      "    \"type\": \"web_search_preview\",\n",
      "    \"user_location\": null,\n",
      "    \"search_context_size\": \"medium\"\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"fetch_paper\",\n",
      "    \"parameters\": {\n",
      "      \"properties\": {\n",
      "        \"arxiv_id\": {\n",
      "          \"description\": \"The arXiv ID (e.g., '1706.03762')\",\n",
      "          \"title\": \"Arxiv Id\",\n",
      "          \"type\": \"string\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"arxiv_id\"\n",
      "      ],\n",
      "      \"title\": \"fetch_paper_args\",\n",
      "      \"type\": \"object\",\n",
      "      \"additionalProperties\": false\n",
      "    },\n",
      "    \"strict\": true,\n",
      "    \"type\": \"function\",\n",
      "    \"description\": \"Fetches paper information from arXiv given its ID.\"\n",
      "  }\n",
      "]\n",
      "Stream: False\n",
      "Tool choice: NOT_GIVEN\n",
      "Response format: NOT_GIVEN\n",
      "Previous response id: None\n",
      "\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/responses', 'headers': {'User-Agent': 'Agents/Python 0.0.11'}, 'files': None, 'json_data': {'input': [{'content': 'check my draft proposal at draft_proposal.txt and give me feedback on it based on what is currently available in the web about this topic', 'role': 'user'}], 'model': 'gpt-4o', 'include': [], 'instructions': '\\nYou are a helpful Research Assistant which helps professors in various tasks.\\nMake sure to answer all questions asked. When asked about current information,\\nuse the WebSearchTool to find the latest information.\\n', 'stream': False, 'tools': [{'type': 'web_search_preview', 'user_location': None, 'search_context_size': 'medium'}, {'name': 'fetch_paper', 'parameters': {'properties': {'arxiv_id': {'description': \"The arXiv ID (e.g., '1706.03762')\", 'title': 'Arxiv Id', 'type': 'string'}}, 'required': ['arxiv_id'], 'title': 'fetch_paper_args', 'type': 'object', 'additionalProperties': False}, 'strict': True, 'type': 'function', 'description': 'Fetches paper information from arXiv given its ID.'}]}}\n",
      "DEBUG:httpcore.connection:close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11df46cd0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x11bc45010> server_hostname='api.openai.com' timeout=5.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11eaa7a50>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06:36:22.749 OpenAI Agents trace: Agent workflow\n",
      "06:36:22.750   Agent run: 'Research Assistant'\n",
      "06:36:22.752     Responses API with 'gpt-4o'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 20 Apr 2025 06:36:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-thoiewvv8uw64smqtyk9d229'), (b'x-request-id', b'req_271577e533f15b6429422d421d2e032d'), (b'openai-processing-ms', b'1161'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=V5Rn84r1xq.53PrfifZw7VD5eB6ssSaWFrUuJ94CuA4-1745130984-1.0.1.1-XW21auRTUBRtPG53lwAwh6PXap4FwIKimSVMiekQhvayrfFCDhh1OZljbJHuNorGhg9pYwAVHtZqAVaJTdWV0_CqYzOKjgytnhyUgA8ZURA; path=/; expires=Sun, 20-Apr-25 07:06:24 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9332a082ced87664-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/responses \"200 OK\"\n",
      "DEBUG:openai.agents:LLM resp:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"msg_680495e791808191bd68b94de4af5ec1067580d01d640fe9\",\n",
      "    \"content\": [\n",
      "      {\n",
      "        \"annotations\": [],\n",
      "        \"text\": \"I currently don't have the ability to view or access files directly. If you could provide the text or main points of your draft proposal here, I'd be happy to help you with feedback based on current information.\",\n",
      "        \"type\": \"output_text\"\n",
      "      }\n",
      "    ],\n",
      "    \"role\": \"assistant\",\n",
      "    \"status\": \"completed\",\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "DEBUG:openai.agents:Resetting current trace\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I currently don't have the ability to view or access files directly. If you could provide the text or main points of your draft proposal here, I'd be happy to help you with feedback based on current information.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from agents import WebSearchTool\n",
    "\n",
    "\n",
    "agent_2 = Agent(\n",
    "    name=\"Research Assistant\",\n",
    "    instructions=\n",
    "    \"\"\"\n",
    "You are a helpful Research Assistant which helps professors in various tasks.\n",
    "Make sure to answer all questions asked. When asked about current information,\n",
    "use the WebSearchTool to find the latest information.\n",
    "\"\"\",\n",
    "    tools=[WebSearchTool(), fetch_paper],\n",
    ")\n",
    "\n",
    "result = await Runner.run(\n",
    "    agent_2,\n",
    "    \"check my draft proposal at draft_proposal.txt and give me feedback on it based on what is currently available in the web about this topic\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:openai.agents:Creating trace Agent workflow with id trace_6fe72e8e53b147ffb0638cf15b855880\n",
      "DEBUG:openai.agents:Setting current trace: trace_6fe72e8e53b147ffb0638cf15b855880\n",
      "DEBUG:openai.agents:Creating span <agents.tracing.span_data.AgentSpanData object at 0x11e064cb0> with id None\n",
      "DEBUG:openai.agents:Running agent Research Assistant (turn 1)\n",
      "DEBUG:openai.agents:Creating span <agents.tracing.span_data.ResponseSpanData object at 0x11e027de0> with id None\n",
      "DEBUG:openai.agents:Calling LLM gpt-4o with input:\n",
      "[\n",
      "  {\n",
      "    \"content\": \"check my draft proposal at draft_proposal.txt and give me feedback on it based on what is currently available in the web about this topic\",\n",
      "    \"role\": \"user\"\n",
      "  }\n",
      "]\n",
      "Tools:\n",
      "[\n",
      "  {\n",
      "    \"type\": \"web_search_preview\",\n",
      "    \"user_location\": null,\n",
      "    \"search_context_size\": \"medium\"\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"fetch_paper\",\n",
      "    \"parameters\": {\n",
      "      \"properties\": {\n",
      "        \"arxiv_id\": {\n",
      "          \"description\": \"The arXiv ID (e.g., '1706.03762')\",\n",
      "          \"title\": \"Arxiv Id\",\n",
      "          \"type\": \"string\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"arxiv_id\"\n",
      "      ],\n",
      "      \"title\": \"fetch_paper_args\",\n",
      "      \"type\": \"object\",\n",
      "      \"additionalProperties\": false\n",
      "    },\n",
      "    \"strict\": true,\n",
      "    \"type\": \"function\",\n",
      "    \"description\": \"Fetches paper information from arXiv given its ID.\"\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"read_local_file\",\n",
      "    \"parameters\": {\n",
      "      \"properties\": {\n",
      "        \"file_path\": {\n",
      "          \"description\": \"Path to the file to read\",\n",
      "          \"title\": \"File Path\",\n",
      "          \"type\": \"string\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"file_path\"\n",
      "      ],\n",
      "      \"title\": \"read_local_file_args\",\n",
      "      \"type\": \"object\",\n",
      "      \"additionalProperties\": false\n",
      "    },\n",
      "    \"strict\": true,\n",
      "    \"type\": \"function\",\n",
      "    \"description\": \"Reads the content of a local file and returns it as a string.\"\n",
      "  }\n",
      "]\n",
      "Stream: False\n",
      "Tool choice: NOT_GIVEN\n",
      "Response format: NOT_GIVEN\n",
      "Previous response id: None\n",
      "\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/responses', 'headers': {'User-Agent': 'Agents/Python 0.0.11'}, 'files': None, 'json_data': {'input': [{'content': 'check my draft proposal at draft_proposal.txt and give me feedback on it based on what is currently available in the web about this topic', 'role': 'user'}], 'model': 'gpt-4o', 'include': [], 'instructions': '\\nYou are a helpful Research Assistant which helps professors in various tasks.\\nMake sure to answer all questions asked. When asked about current information,\\nuse the WebSearchTool to find the latest information.\\n', 'stream': False, 'tools': [{'type': 'web_search_preview', 'user_location': None, 'search_context_size': 'medium'}, {'name': 'fetch_paper', 'parameters': {'properties': {'arxiv_id': {'description': \"The arXiv ID (e.g., '1706.03762')\", 'title': 'Arxiv Id', 'type': 'string'}}, 'required': ['arxiv_id'], 'title': 'fetch_paper_args', 'type': 'object', 'additionalProperties': False}, 'strict': True, 'type': 'function', 'description': 'Fetches paper information from arXiv given its ID.'}, {'name': 'read_local_file', 'parameters': {'properties': {'file_path': {'description': 'Path to the file to read', 'title': 'File Path', 'type': 'string'}}, 'required': ['file_path'], 'title': 'read_local_file_args', 'type': 'object', 'additionalProperties': False}, 'strict': True, 'type': 'function', 'description': 'Reads the content of a local file and returns it as a string.'}]}}\n",
      "DEBUG:httpcore.connection:close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11c053f90>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x11bc45010> server_hostname='api.openai.com' timeout=5.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11e9c7210>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06:38:22.260 OpenAI Agents trace: Agent workflow\n",
      "06:38:22.261   Agent run: 'Research Assistant'\n",
      "06:38:22.263     Responses API with 'gpt-4o'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 20 Apr 2025 06:38:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-thoiewvv8uw64smqtyk9d229'), (b'x-request-id', b'req_ce1213ec9ee5458afa27e29c6dc1d6b8'), (b'openai-processing-ms', b'648'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9332a36dba1f2849-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/responses \"200 OK\"\n",
      "DEBUG:openai.agents:LLM resp:\n",
      "[\n",
      "  {\n",
      "    \"arguments\": \"{\\\"file_path\\\":\\\"draft_proposal.txt\\\"}\",\n",
      "    \"call_id\": \"call_19iwHao2aMH5C63wuCFaRe4V\",\n",
      "    \"name\": \"read_local_file\",\n",
      "    \"type\": \"function_call\",\n",
      "    \"id\": \"fc_6804965eea54819184b5e9b44ec8124e00dc7f70c1cd98b6\",\n",
      "    \"status\": \"completed\"\n",
      "  }\n",
      "]\n",
      "\n",
      "DEBUG:openai.agents:Creating span <agents.tracing.span_data.FunctionSpanData object at 0x11ea172f0> with id None\n",
      "DEBUG:openai.agents:Invoking tool read_local_file with input {\"file_path\":\"draft_proposal.txt\"}\n",
      "DEBUG:openai.agents:Tool call args: ['draft_proposal.txt'], kwargs: {}\n",
      "DEBUG:openai.agents:Tool read_local_file returned # Novel AI Research Proposal\n",
      "\n",
      "## Title\n",
      "\"Adaptive Context Management for Large Language Models: Optimizing Information Retrieval and Utilization in Multi-Agent Systems\"\n",
      "\n",
      "## Abstract\n",
      "This paper proposes a novel framework for dynamic context management in large language models (LLMs), particularly in multi-agent systems. We address the critical challenge of context window limitations by developing an adaptive mechanism that intelligently selects, prioritizes, and compresses contextual information based on task relevance and information density. Our approach combines transformer-based attention mechanisms with reinforcement learning to optimize the retrieval and utilization of context across multiple agents working collaboratively on complex tasks.\n",
      "\n",
      "## Introduction\n",
      "As LLMs continue to evolve, their ability to process and utilize context effectively remains a significant bottleneck. Current models either suffer from limited context windows or inefficient use of available context, leading to suboptimal performance in complex reasoning tasks. This limitation is particularly pronounced in multi-agent systems where information sharing and context coordination are essential.\n",
      "\n",
      "## Proposed Methodology\n",
      "Our approach introduces three key innovations:\n",
      "\n",
      "1. **Dynamic Context Prioritization**: A mechanism that scores and ranks contextual elements based on their relevance to the current task, semantic richness, and potential utility.\n",
      "\n",
      "2. **Cross-Agent Context Sharing Protocol**: A framework for efficient information exchange between agents, minimizing redundancy while maximizing collective knowledge.\n",
      "\n",
      "3. **Adaptive Compression Techniques**: Methods to condense context without losing critical information, using a combination of semantic compression and importance-weighted summarization.\n",
      "\n",
      "## Preliminary Experiments\n",
      "Initial experiments on benchmark datasets show promising results:\n",
      "- 27% reduction in context size while maintaining equivalent performance\n",
      "- 18% improvement in multi-agent collaborative task completion\n",
      "- 35% decrease in redundant information processing across agent boundaries\n",
      "\n",
      "## Expected Impact\n",
      "This research has the potential to significantly advance the field of multi-agent LLM systems by addressing fundamental limitations in context management. Applications range from more efficient code generation and debugging to complex reasoning tasks requiring coordination between specialized agents.\n",
      "\n",
      "## Timeline and Resources\n",
      "- Phase 1 (3 months): Framework development and baseline testing\n",
      "- Phase 2 (4 months): Implementation of adaptive algorithms and inter-agent protocols\n",
      "- Phase 3 (5 months): Comprehensive evaluation and optimization\n",
      "\n",
      "Required resources include access to state-of-the-art LLM APIs, computational infrastructure for training and evaluation, and benchmark datasets for standardized testing.\n",
      "\n",
      "DEBUG:openai.agents:Running agent Research Assistant (turn 2)\n",
      "DEBUG:openai.agents:Creating span <agents.tracing.span_data.ResponseSpanData object at 0x11e982fd0> with id None\n",
      "DEBUG:openai.agents:Calling LLM gpt-4o with input:\n",
      "[\n",
      "  {\n",
      "    \"content\": \"check my draft proposal at draft_proposal.txt and give me feedback on it based on what is currently available in the web about this topic\",\n",
      "    \"role\": \"user\"\n",
      "  },\n",
      "  {\n",
      "    \"arguments\": \"{\\\"file_path\\\":\\\"draft_proposal.txt\\\"}\",\n",
      "    \"call_id\": \"call_19iwHao2aMH5C63wuCFaRe4V\",\n",
      "    \"name\": \"read_local_file\",\n",
      "    \"type\": \"function_call\",\n",
      "    \"id\": \"fc_6804965eea54819184b5e9b44ec8124e00dc7f70c1cd98b6\",\n",
      "    \"status\": \"completed\"\n",
      "  },\n",
      "  {\n",
      "    \"call_id\": \"call_19iwHao2aMH5C63wuCFaRe4V\",\n",
      "    \"output\": \"# Novel AI Research Proposal\\n\\n## Title\\n\\\"Adaptive Context Management for Large Language Models: Optimizing Information Retrieval and Utilization in Multi-Agent Systems\\\"\\n\\n## Abstract\\nThis paper proposes a novel framework for dynamic context management in large language models (LLMs), particularly in multi-agent systems. We address the critical challenge of context window limitations by developing an adaptive mechanism that intelligently selects, prioritizes, and compresses contextual information based on task relevance and information density. Our approach combines transformer-based attention mechanisms with reinforcement learning to optimize the retrieval and utilization of context across multiple agents working collaboratively on complex tasks.\\n\\n## Introduction\\nAs LLMs continue to evolve, their ability to process and utilize context effectively remains a significant bottleneck. Current models either suffer from limited context windows or inefficient use of available context, leading to suboptimal performance in complex reasoning tasks. This limitation is particularly pronounced in multi-agent systems where information sharing and context coordination are essential.\\n\\n## Proposed Methodology\\nOur approach introduces three key innovations:\\n\\n1. **Dynamic Context Prioritization**: A mechanism that scores and ranks contextual elements based on their relevance to the current task, semantic richness, and potential utility.\\n\\n2. **Cross-Agent Context Sharing Protocol**: A framework for efficient information exchange between agents, minimizing redundancy while maximizing collective knowledge.\\n\\n3. **Adaptive Compression Techniques**: Methods to condense context without losing critical information, using a combination of semantic compression and importance-weighted summarization.\\n\\n## Preliminary Experiments\\nInitial experiments on benchmark datasets show promising results:\\n- 27% reduction in context size while maintaining equivalent performance\\n- 18% improvement in multi-agent collaborative task completion\\n- 35% decrease in redundant information processing across agent boundaries\\n\\n## Expected Impact\\nThis research has the potential to significantly advance the field of multi-agent LLM systems by addressing fundamental limitations in context management. Applications range from more efficient code generation and debugging to complex reasoning tasks requiring coordination between specialized agents.\\n\\n## Timeline and Resources\\n- Phase 1 (3 months): Framework development and baseline testing\\n- Phase 2 (4 months): Implementation of adaptive algorithms and inter-agent protocols\\n- Phase 3 (5 months): Comprehensive evaluation and optimization\\n\\nRequired resources include access to state-of-the-art LLM APIs, computational infrastructure for training and evaluation, and benchmark datasets for standardized testing.\\n\",\n",
      "    \"type\": \"function_call_output\"\n",
      "  }\n",
      "]\n",
      "Tools:\n",
      "[\n",
      "  {\n",
      "    \"type\": \"web_search_preview\",\n",
      "    \"user_location\": null,\n",
      "    \"search_context_size\": \"medium\"\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"fetch_paper\",\n",
      "    \"parameters\": {\n",
      "      \"properties\": {\n",
      "        \"arxiv_id\": {\n",
      "          \"description\": \"The arXiv ID (e.g., '1706.03762')\",\n",
      "          \"title\": \"Arxiv Id\",\n",
      "          \"type\": \"string\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"arxiv_id\"\n",
      "      ],\n",
      "      \"title\": \"fetch_paper_args\",\n",
      "      \"type\": \"object\",\n",
      "      \"additionalProperties\": false\n",
      "    },\n",
      "    \"strict\": true,\n",
      "    \"type\": \"function\",\n",
      "    \"description\": \"Fetches paper information from arXiv given its ID.\"\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"read_local_file\",\n",
      "    \"parameters\": {\n",
      "      \"properties\": {\n",
      "        \"file_path\": {\n",
      "          \"description\": \"Path to the file to read\",\n",
      "          \"title\": \"File Path\",\n",
      "          \"type\": \"string\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"file_path\"\n",
      "      ],\n",
      "      \"title\": \"read_local_file_args\",\n",
      "      \"type\": \"object\",\n",
      "      \"additionalProperties\": false\n",
      "    },\n",
      "    \"strict\": true,\n",
      "    \"type\": \"function\",\n",
      "    \"description\": \"Reads the content of a local file and returns it as a string.\"\n",
      "  }\n",
      "]\n",
      "Stream: False\n",
      "Tool choice: NOT_GIVEN\n",
      "Response format: NOT_GIVEN\n",
      "Previous response id: None\n",
      "\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/responses', 'headers': {'User-Agent': 'Agents/Python 0.0.11'}, 'files': None, 'json_data': {'input': [{'content': 'check my draft proposal at draft_proposal.txt and give me feedback on it based on what is currently available in the web about this topic', 'role': 'user'}, {'arguments': '{\"file_path\":\"draft_proposal.txt\"}', 'call_id': 'call_19iwHao2aMH5C63wuCFaRe4V', 'name': 'read_local_file', 'type': 'function_call', 'id': 'fc_6804965eea54819184b5e9b44ec8124e00dc7f70c1cd98b6', 'status': 'completed'}, {'call_id': 'call_19iwHao2aMH5C63wuCFaRe4V', 'output': '# Novel AI Research Proposal\\n\\n## Title\\n\"Adaptive Context Management for Large Language Models: Optimizing Information Retrieval and Utilization in Multi-Agent Systems\"\\n\\n## Abstract\\nThis paper proposes a novel framework for dynamic context management in large language models (LLMs), particularly in multi-agent systems. We address the critical challenge of context window limitations by developing an adaptive mechanism that intelligently selects, prioritizes, and compresses contextual information based on task relevance and information density. Our approach combines transformer-based attention mechanisms with reinforcement learning to optimize the retrieval and utilization of context across multiple agents working collaboratively on complex tasks.\\n\\n## Introduction\\nAs LLMs continue to evolve, their ability to process and utilize context effectively remains a significant bottleneck. Current models either suffer from limited context windows or inefficient use of available context, leading to suboptimal performance in complex reasoning tasks. This limitation is particularly pronounced in multi-agent systems where information sharing and context coordination are essential.\\n\\n## Proposed Methodology\\nOur approach introduces three key innovations:\\n\\n1. **Dynamic Context Prioritization**: A mechanism that scores and ranks contextual elements based on their relevance to the current task, semantic richness, and potential utility.\\n\\n2. **Cross-Agent Context Sharing Protocol**: A framework for efficient information exchange between agents, minimizing redundancy while maximizing collective knowledge.\\n\\n3. **Adaptive Compression Techniques**: Methods to condense context without losing critical information, using a combination of semantic compression and importance-weighted summarization.\\n\\n## Preliminary Experiments\\nInitial experiments on benchmark datasets show promising results:\\n- 27% reduction in context size while maintaining equivalent performance\\n- 18% improvement in multi-agent collaborative task completion\\n- 35% decrease in redundant information processing across agent boundaries\\n\\n## Expected Impact\\nThis research has the potential to significantly advance the field of multi-agent LLM systems by addressing fundamental limitations in context management. Applications range from more efficient code generation and debugging to complex reasoning tasks requiring coordination between specialized agents.\\n\\n## Timeline and Resources\\n- Phase 1 (3 months): Framework development and baseline testing\\n- Phase 2 (4 months): Implementation of adaptive algorithms and inter-agent protocols\\n- Phase 3 (5 months): Comprehensive evaluation and optimization\\n\\nRequired resources include access to state-of-the-art LLM APIs, computational infrastructure for training and evaluation, and benchmark datasets for standardized testing.\\n', 'type': 'function_call_output'}], 'model': 'gpt-4o', 'include': [], 'instructions': '\\nYou are a helpful Research Assistant which helps professors in various tasks.\\nMake sure to answer all questions asked. When asked about current information,\\nuse the WebSearchTool to find the latest information.\\n', 'stream': False, 'tools': [{'type': 'web_search_preview', 'user_location': None, 'search_context_size': 'medium'}, {'name': 'fetch_paper', 'parameters': {'properties': {'arxiv_id': {'description': \"The arXiv ID (e.g., '1706.03762')\", 'title': 'Arxiv Id', 'type': 'string'}}, 'required': ['arxiv_id'], 'title': 'fetch_paper_args', 'type': 'object', 'additionalProperties': False}, 'strict': True, 'type': 'function', 'description': 'Fetches paper information from arXiv given its ID.'}, {'name': 'read_local_file', 'parameters': {'properties': {'file_path': {'description': 'Path to the file to read', 'title': 'File Path', 'type': 'string'}}, 'required': ['file_path'], 'title': 'read_local_file_args', 'type': 'object', 'additionalProperties': False}, 'strict': True, 'type': 'function', 'description': 'Reads the content of a local file and returns it as a string.'}]}}\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06:38:23.101     Function: read_local_file\n",
      "06:38:23.105     Responses API with 'gpt-4o'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 20 Apr 2025 06:38:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-thoiewvv8uw64smqtyk9d229'), (b'x-request-id', b'req_0c0a8dd906a6adaf06e597b6850a0ea7'), (b'openai-processing-ms', b'8157'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9332a372cd992849-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/responses \"200 OK\"\n",
      "DEBUG:openai.agents:LLM resp:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"ws_6804966030948191b1ca095eb6869ad000dc7f70c1cd98b6\",\n",
      "    \"status\": \"completed\",\n",
      "    \"type\": \"web_search_call\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"msg_68049662fbc48191b64594b1db24f43000dc7f70c1cd98b6\",\n",
      "    \"content\": [\n",
      "      {\n",
      "        \"annotations\": [\n",
      "          {\n",
      "            \"end_index\": 865,\n",
      "            \"start_index\": 798,\n",
      "            \"title\": \"[2402.01968v1] A Survey on Context-Aware Multi-Agent Systems: Techniques, Challenges and Future Directions\",\n",
      "            \"type\": \"url_citation\",\n",
      "            \"url\": \"https://arxiv.org/abs/2402.01968v1?utm_source=openai\"\n",
      "          }\n",
      "        ],\n",
      "        \"text\": \"Your draft proposal, \\\"Adaptive Context Management for Large Language Models: Optimizing Information Retrieval and Utilization in Multi-Agent Systems,\\\" presents a compelling approach to enhancing context management in large language models (LLMs) within multi-agent systems. To strengthen your proposal, consider the following feedback based on recent research:\\n\\n**1. Incorporate Recent Surveys and Frameworks:**\\nA comprehensive survey titled \\\"A Survey on Context-Aware Multi-Agent Systems: Techniques, Challenges and Future Directions\\\" by Hung Du et al. (2024) provides an in-depth analysis of integrating context-aware systems with multi-agent systems. This work outlines a general process model applicable across various domains, which could serve as a foundational reference for your framework. ([arxiv.org](https://arxiv.org/abs/2402.01968v1?utm_source=openai))\\n\\n**2. Address Identified Challenges:**\\nThe aforementioned survey highlights several challenges in context-aware multi-agent systems, such as:\\n- **Dynamic Environment Adaptation:** Ensuring agents can adapt to rapidly changing contexts.\\n- **Efficient Communication:** Developing protocols that minimize redundancy and maximize information utility.\\n- **Scalability:** Designing systems that maintain performance as the number of agents increases.\\n\\nExplicitly addressing these challenges in your proposal will demonstrate awareness of current research gaps and the relevance of your work.\\n\\n**3. Detail the Adaptive Mechanism:**\\nYour proposal mentions combining transformer-based attention mechanisms with reinforcement learning for context management. Providing a more detailed explanation of how these components interact and contribute to dynamic context prioritization will clarify the novelty and feasibility of your approach.\\n\\n**4. Expand on Preliminary Experiments:**\\nWhile initial results are promising, including more details about the experimental setup, datasets used, and specific metrics will enhance the credibility of your findings. Comparing your results with existing benchmarks in the field can further substantiate the effectiveness of your proposed framework.\\n\\n**5. Clarify Resource Requirements:**\\nSpecifying the exact computational resources, such as GPU specifications, memory requirements, and estimated computational time, will provide a clearer picture of the feasibility and scalability of your project.\\n\\nBy integrating these considerations, your proposal will align more closely with current research trends and address pertinent challenges in the field, thereby strengthening its impact and feasibility. \",\n",
      "        \"type\": \"output_text\"\n",
      "      }\n",
      "    ],\n",
      "    \"role\": \"assistant\",\n",
      "    \"status\": \"completed\",\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "DEBUG:openai.agents:Resetting current trace\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your draft proposal, \"Adaptive Context Management for Large Language Models: Optimizing Information Retrieval and Utilization in Multi-Agent Systems,\" presents a compelling approach to enhancing context management in large language models (LLMs) within multi-agent systems. To strengthen your proposal, consider the following feedback based on recent research:\n",
      "\n",
      "**1. Incorporate Recent Surveys and Frameworks:**\n",
      "A comprehensive survey titled \"A Survey on Context-Aware Multi-Agent Systems: Techniques, Challenges and Future Directions\" by Hung Du et al. (2024) provides an in-depth analysis of integrating context-aware systems with multi-agent systems. This work outlines a general process model applicable across various domains, which could serve as a foundational reference for your framework. ([arxiv.org](https://arxiv.org/abs/2402.01968v1?utm_source=openai))\n",
      "\n",
      "**2. Address Identified Challenges:**\n",
      "The aforementioned survey highlights several challenges in context-aware multi-agent systems, such as:\n",
      "- **Dynamic Environment Adaptation:** Ensuring agents can adapt to rapidly changing contexts.\n",
      "- **Efficient Communication:** Developing protocols that minimize redundancy and maximize information utility.\n",
      "- **Scalability:** Designing systems that maintain performance as the number of agents increases.\n",
      "\n",
      "Explicitly addressing these challenges in your proposal will demonstrate awareness of current research gaps and the relevance of your work.\n",
      "\n",
      "**3. Detail the Adaptive Mechanism:**\n",
      "Your proposal mentions combining transformer-based attention mechanisms with reinforcement learning for context management. Providing a more detailed explanation of how these components interact and contribute to dynamic context prioritization will clarify the novelty and feasibility of your approach.\n",
      "\n",
      "**4. Expand on Preliminary Experiments:**\n",
      "While initial results are promising, including more details about the experimental setup, datasets used, and specific metrics will enhance the credibility of your findings. Comparing your results with existing benchmarks in the field can further substantiate the effectiveness of your proposed framework.\n",
      "\n",
      "**5. Clarify Resource Requirements:**\n",
      "Specifying the exact computational resources, such as GPU specifications, memory requirements, and estimated computational time, will provide a clearer picture of the feasibility and scalability of your project.\n",
      "\n",
      "By integrating these considerations, your proposal will align more closely with current research trends and address pertinent challenges in the field, thereby strengthening its impact and feasibility. \n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from agents import function_tool\n",
    "\n",
    "\n",
    "@function_tool\n",
    "async def read_local_file(\n",
    "    file_path: Annotated[str, \"Path to the file to read\"]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Reads the content of a local file and returns it as a string.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the file to read\n",
    "        \n",
    "    Returns:\n",
    "        The content of the file as a string\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If the file does not exist\n",
    "        PermissionError: If the file cannot be read due to permission issues\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read()\n",
    "        return content\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: File '{file_path}' not found.\"\n",
    "    except PermissionError:\n",
    "        return f\"Error: Permission denied when trying to read '{file_path}'.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error reading file: {str(e)}\"\n",
    "\n",
    "\n",
    "agent_3 = Agent(\n",
    "    name=\"Research Assistant\",\n",
    "    instructions=\n",
    "    \"\"\"\n",
    "You are a helpful Research Assistant which helps professors in various tasks.\n",
    "Make sure to answer all questions asked. When asked about current information,\n",
    "use the WebSearchTool to find the latest information.\n",
    "\"\"\",\n",
    "    tools=[WebSearchTool(), fetch_paper, read_local_file],\n",
    ")\n",
    "\n",
    "result = await Runner.run(\n",
    "    agent_3,\n",
    "    \"check my draft proposal at draft_proposal.txt and give me feedback on it based on what is currently available in the web about this topic\")\n",
    "print(result.final_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
